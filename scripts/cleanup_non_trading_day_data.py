#!/usr/bin/env python3
"""
éäº¤æ˜“æ—¥æ•°æ®æ¸…ç†è„šæœ¬

æ­¤è„šæœ¬ç”¨äºå®‰å…¨åœ°åˆ é™¤éäº¤æ˜“æ—¥çš„ç”¨æˆ·æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
1. user_account_info è¡¨ä¸­çš„éäº¤æ˜“æ—¥æ•°æ®
2. user_positions è¡¨ä¸­çš„éäº¤æ˜“æ—¥æ•°æ®

æ³¨æ„ï¼šuser_transactions ä¸éœ€è¦æ¸…ç†ï¼Œå› ä¸ºäº¤æ˜“æœ¬æ¥å°±ä¸ä¼šæ¯å¤©éƒ½æœ‰

ä½¿ç”¨æ–¹æ³•:
    python scripts/cleanup_non_trading_day_data.py --dry-run     # é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…åˆ é™¤
    python scripts/cleanup_non_trading_day_data.py --execute    # æ‰§è¡Œåˆ é™¤
"""

import argparse
import logging
from datetime import datetime
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from duckdb_impl import DuckDBDatabase
from config import get_config

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_non_trading_day_data(db):
    """æŸ¥è¯¢éäº¤æ˜“æ—¥æ•°æ®"""
    logger.info("æŸ¥è¯¢éäº¤æ˜“æ—¥æ•°æ®...")

    # æŸ¥è¯¢ user_account_info ä¸­çš„éäº¤æ˜“æ—¥æ•°æ®
    account_sql = """
    SELECT ua.user_id, ua.info_date, 'user_account_info' as table_name
    FROM user_account_info ua
    LEFT JOIN (SELECT DISTINCT day FROM price_data) pd ON ua.info_date = pd.day
    WHERE pd.day IS NULL AND ua.info_date >= '2025-05-12'
    ORDER BY ua.info_date, ua.user_id
    """

    # æŸ¥è¯¢ user_positions ä¸­çš„éäº¤æ˜“æ—¥æ•°æ®
    position_sql = """
    SELECT up.user_id, up.position_date, up.stock_code, 'user_positions' as table_name
    FROM user_positions up
    LEFT JOIN (SELECT DISTINCT day FROM price_data) pd ON up.position_date = pd.day
    WHERE pd.day IS NULL AND up.position_date >= '2025-05-12'
    ORDER BY up.position_date, up.user_id, up.stock_code
    """

    account_data = db.query_data(account_sql)
    position_data = db.query_data(position_sql)

    logger.info(f"å‘ç° user_account_info éäº¤æ˜“æ—¥è®°å½•: {len(account_data)} æ¡")
    logger.info(f"å‘ç° user_positions éäº¤æ˜“æ—¥è®°å½•: {len(position_data)} æ¡")

    return account_data, position_data

def preview_cleanup(account_data, position_data):
    """é¢„è§ˆå°†è¦åˆ é™¤çš„æ•°æ®"""
    logger.info("\n" + "="*60)
    logger.info("ğŸ“‹ é¢„è§ˆå°†è¦åˆ é™¤çš„æ•°æ®")
    logger.info("="*60)

    if len(account_data) > 0:
        logger.info(f"\nğŸ“Š user_account_info è¡¨ ({len(account_data)} æ¡è®°å½•):")
        logger.info("æ—¥æœŸèŒƒå›´:")
        dates = sorted(set([row[1].strftime('%Y-%m-%d') if hasattr(row[1], 'strftime') else str(row[1]) for row in account_data]))
        logger.info(f"  - é¦–ä¸ªæ—¥æœŸ: {dates[0]}")
        logger.info(f"  - æœ€åæ—¥æœŸ: {dates[-1]}")
        logger.info(f"  - æ¶‰åŠæ—¥æœŸ: {len(dates)} å¤©")

        users = set([str(row[0]) for row in account_data])
        logger.info(f"  - æ¶‰åŠç”¨æˆ·: {len(users)} ä¸ª")
        logger.info(f"  - ç”¨æˆ·åˆ—è¡¨: {', '.join(list(users)[:5])}{'...' if len(users) > 5 else ''}")

        # æ˜¾ç¤ºå‰å‡ æ¡è®°å½•
        logger.info("å‰5æ¡è®°å½•:")
        for i, row in enumerate(account_data[:5]):
            date_str = row[1].strftime('%Y-%m-%d') if hasattr(row[1], 'strftime') else str(row[1])
            logger.info(f"  {i+1}. ç”¨æˆ·: {row[0]}, æ—¥æœŸ: {date_str}")

    if len(position_data) > 0:
        logger.info(f"\nğŸ“ˆ user_positions è¡¨ ({len(position_data)} æ¡è®°å½•):")
        dates = sorted(set([row[1].strftime('%Y-%m-%d') if hasattr(row[1], 'strftime') else str(row[1]) for row in position_data]))
        logger.info(f"  - é¦–ä¸ªæ—¥æœŸ: {dates[0]}")
        logger.info(f"  - æœ€åæ—¥æœŸ: {dates[-1]}")
        logger.info(f"  - æ¶‰åŠæ—¥æœŸ: {len(dates)} å¤©")

        users = set([str(row[0]) for row in position_data])
        stocks = set([str(row[2]) for row in position_data])
        logger.info(f"  - æ¶‰åŠç”¨æˆ·: {len(users)} ä¸ª")
        logger.info(f"  - æ¶‰åŠè‚¡ç¥¨: {len(stocks)} åª")

        # æ˜¾ç¤ºå‰å‡ æ¡è®°å½•
        logger.info("å‰5æ¡è®°å½•:")
        for i, row in enumerate(position_data[:5]):
            date_str = row[1].strftime('%Y-%m-%d') if hasattr(row[1], 'strftime') else str(row[1])
            logger.info(f"  {i+1}. ç”¨æˆ·: {row[0]}, æ—¥æœŸ: {date_str}, è‚¡ç¥¨: {row[2]}")

def execute_cleanup(db, account_data, position_data):
    """æ‰§è¡Œæ•°æ®æ¸…ç†"""
    logger.info("\n" + "="*60)
    logger.info("ğŸ—‘ï¸  å¼€å§‹æ‰§è¡Œæ•°æ®æ¸…ç†")
    logger.info("="*60)

    total_deleted = 0

    try:
        # æ¸…ç† user_account_info
        if len(account_data) > 0:
            logger.info(f"\nğŸ”„ æ¸…ç† user_account_info è¡¨...")
            delete_account_sql = """
            DELETE FROM user_account_info
            WHERE info_date NOT IN (SELECT DISTINCT day FROM price_data)
              AND info_date >= '2025-05-12'
            """

            db.execute(delete_account_sql)
            logger.info(f"âœ… å·²åˆ é™¤ user_account_info ä¸­ {len(account_data)} æ¡éäº¤æ˜“æ—¥è®°å½•")
            total_deleted += len(account_data)

        # æ¸…ç† user_positions
        if len(position_data) > 0:
            logger.info(f"\nğŸ”„ æ¸…ç† user_positions è¡¨...")
            delete_position_sql = """
            DELETE FROM user_positions
            WHERE position_date NOT IN (SELECT DISTINCT day FROM price_data)
              AND position_date >= '2025-05-12'
            """

            db.execute(delete_position_sql)
            logger.info(f"âœ… å·²åˆ é™¤ user_positions ä¸­ {len(position_data)} æ¡éäº¤æ˜“æ—¥è®°å½•")
            total_deleted += len(position_data)

        logger.info(f"\nğŸ‰ æ¸…ç†å®Œæˆ! æ€»å…±åˆ é™¤äº† {total_deleted} æ¡è®°å½•")
        logger.info(f"æ¸…ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    except Exception as e:
        logger.error(f"âŒ åˆ é™¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise

def main():
    parser = argparse.ArgumentParser(description="æ¸…ç†ç”¨æˆ·è¡¨ä¸­çš„éäº¤æ˜“æ—¥æ•°æ®")
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼Œåªæ˜¾ç¤ºå°†è¦åˆ é™¤çš„æ•°æ®ï¼Œä¸å®é™…æ‰§è¡Œ")
    group.add_argument("--execute", action="store_true", help="æ‰§è¡Œåˆ é™¤æ“ä½œ")

    args = parser.parse_args()

    logger.info("ğŸš€ å¯åŠ¨éäº¤æ˜“æ—¥æ•°æ®æ¸…ç†è„šæœ¬")
    logger.info(f"æ¨¡å¼: {'é¢„è§ˆ' if args.dry_run else 'æ‰§è¡Œåˆ é™¤'}")

    try:
        # è·å–æ•°æ®åº“è¿æ¥
        config = get_config()
        db_path = config.database.path
        db = DuckDBDatabase(db_path)
        db.connect()
        logger.info(f"âœ… å·²è¿æ¥åˆ°æ•°æ®åº“: {db_path}")

        # æŸ¥è¯¢éäº¤æ˜“æ—¥æ•°æ®
        account_data, position_data = get_non_trading_day_data(db)

        if len(account_data) == 0 and len(position_data) == 0:
            logger.info("âœ¨ æœªå‘ç°éœ€è¦æ¸…ç†çš„éäº¤æ˜“æ—¥æ•°æ®")
            return

        # é¢„è§ˆæ•°æ®
        preview_cleanup(account_data, position_data)

        if args.dry_run:
            logger.info("\nğŸ” è¿™æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œæ²¡æœ‰å®é™…åˆ é™¤ä»»ä½•æ•°æ®")
            logger.info("ğŸ’¡ è¦æ‰§è¡Œåˆ é™¤ï¼Œè¯·ä½¿ç”¨ --execute å‚æ•°")
        else:
            # æ‰§è¡Œç¡®è®¤
            total_records = len(account_data) + len(position_data)
            logger.info(f"\nâš ï¸  ç¡®è®¤åˆ é™¤ {total_records} æ¡éäº¤æ˜“æ—¥æ•°æ®ï¼Ÿ")
            logger.info("æ­¤æ“ä½œä¸å¯æ’¤é”€!")

            confirm = input("è¾“å…¥ 'YES' ç¡®è®¤æ‰§è¡Œåˆ é™¤: ")
            if confirm != 'YES':
                logger.info("âŒ æ“ä½œå·²å–æ¶ˆ")
                return

            # æ‰§è¡Œæ¸…ç†
            execute_cleanup(db, account_data, position_data)

    except Exception as e:
        logger.error(f"âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        if 'db' in locals():
            db.close()
            logger.info("ğŸ“ æ•°æ®åº“è¿æ¥å·²å…³é—­")

if __name__ == "__main__":
    main()