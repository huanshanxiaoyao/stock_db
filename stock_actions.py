#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨æ•°æ®ç›¸å…³æ“ä½œå‡½æ•°
"""

import logging
from datetime import datetime, timedelta
from api import create_api
from data_source import DataType
from services.update_service import UpdateService
from common.date_utils import get_trading_days, get_last_trading_day

logger = logging.getLogger(__name__)

# æ”¯æŒçš„æ•°æ®è¡¨åˆ—è¡¨ï¼ˆä»DataTypeç±»è·å–ï¼‰
SUPPORTED_TABLES = [
    DataType.STOCK_LIST,
    DataType.PRICE_DATA,
    DataType.BALANCE_SHEET,
    DataType.INCOME_STATEMENT,
    DataType.CASHFLOW_STATEMENT,
    DataType.INDICATOR_DATA,
    DataType.VALUATION_DATA
]

def action_daily(args):
    """æ¯æ—¥æ•°æ®æ›´æ–°"""
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹æ¯æ—¥æ•°æ®æ›´æ–°")

    try:
        # ä½¿ç”¨ create_api åˆ›å»ºAPIå®ä¾‹ï¼ˆæ¨èæ–¹å¼ï¼‰
        api = create_api(db_path=args.db_path)
        api.initialize()

        # è§£æç›®æ ‡æ—¥æœŸå‚æ•°
        target_date = None
        if args.target_date:
            try:
                from datetime import datetime
                target_date = datetime.strptime(args.target_date, '%Y%m%d').date()
                logger.info(f"æŒ‡å®šæ›´æ–°æ—¥æœŸ: {target_date}")
            except ValueError:
                logger.error(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {args.target_date}ï¼Œåº”ä¸ºYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250630")
                return

        # è§£æè¡¨ç±»å‹å‚æ•°
        data_types = None
        if args.tables:
            # è§£æç”¨æˆ·æŒ‡å®šçš„è¡¨ç±»å‹
            table_list = [t.strip() for t in args.tables.split(',')]
            data_types = []

            for table in table_list:
                if table not in SUPPORTED_TABLES:
                    logger.warning(f"ä¸æ”¯æŒçš„è¡¨ç±»å‹: {table}")
                    continue

                # å°†å…·ä½“è¡¨åæ˜ å°„åˆ°æ•°æ®ç±»å‹
                if table in ['price_data', 'valuation_data', 'indicator_data', 'mtss_data']:
                    data_types.append(table)

            if not data_types:
                logger.error("æ²¡æœ‰æœ‰æ•ˆçš„è¡¨ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤çš„å¸‚åœºæ•°æ®æ›´æ–°")
                return

        # ç¡®å®šäº¤æ˜“æ‰€ç±»å‹
        exchange = 'bj' if args.bj_stocks else 'all'

        if target_date:
            logger.info(f"å‡†å¤‡è¿›è¡Œ{'åŒ—äº¤æ‰€' if args.bj_stocks else 'æ‰€æœ‰'}è‚¡ç¥¨åœ¨ {target_date} çš„æ•°æ®æ›´æ–°")
        else:
            logger.info(f"å‡†å¤‡è¿›è¡Œ{'åŒ—äº¤æ‰€' if args.bj_stocks else 'æ‰€æœ‰'}è‚¡ç¥¨çš„æ¯æ—¥å¢é‡æ›´æ–°")

        if data_types:
            logger.info(f"æ›´æ–°æ•°æ®ç±»å‹: {', '.join(data_types)}")

        # é€šè¿‡APIå±‚è°ƒç”¨æ›´æ–°
        if target_date:
            result = api.daily_update(exchange=exchange, data_types=data_types, target_date=target_date)
        else:
            result = api.daily_update(exchange=exchange, data_types=data_types)
        
        # å¤„ç†è¿”å›ç»“æœ
        if result.get('success'):
            update_result = result.get('result', {})
            logger.info("æ¯æ—¥æ›´æ–°å®Œæˆ!")
            logger.info(f"æ›´æ–°æ—¶é—´: {update_result.get('update_time')}")
        else:
            logger.error(f"æ¯æ—¥æ›´æ–°å¤±è´¥: {result.get('message')}")
        
    except Exception as e:
        logger.error(f"æ¯æ—¥æ›´æ–°å¤±è´¥: {e}")
        logging.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    finally:
        api.close()

def action_update_history(args):
    """
    å†å²æ•°æ®æ›´æ–°
    """
    logger.info("å¼€å§‹å†å²æ•°æ®æ›´æ–°...")
    
    api = create_api(db_path=args.db_path)

    api.initialize()
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    all_stock_codes = api.get_stock_list(exchange='BSE' if args.bj_stocks else None)
    if not all_stock_codes:
        logger.error("é”™è¯¯: æ•°æ®åº“ä¸­æ²¡æœ‰è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·å…ˆè¿è¡Œ init å‘½ä»¤")
        return
    
    # æ ¹æ®--bj-stocksé€‰é¡¹è¿‡æ»¤è‚¡ç¥¨
    if getattr(args, 'bj_stocks', False):
        # åªæ›´æ–°åŒ—äº¤æ‰€è‚¡ç¥¨
        stock_codes = [code for code in all_stock_codes if code.endswith('.BJ')]
        logger.info(f"æ‰¾åˆ° {len(stock_codes)} åªåŒ—äº¤æ‰€è‚¡ç¥¨")
        if not stock_codes:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°åŒ—äº¤æ‰€è‚¡ç¥¨")
            return
    else:
        # æ›´æ–°æ‰€æœ‰è‚¡ç¥¨ï¼ˆæ’é™¤åŒ—äº¤æ‰€ï¼‰
        stock_codes = all_stock_codes
    
    # è§£æè¦æ›´æ–°çš„è¡¨
    tables_to_update = []
    if args.tables:
        tables_to_update = [t.strip() for t in args.tables.split(',')]
    else:
        tables_to_update = SUPPORTED_TABLES
    
    # éªŒè¯è¡¨å
    invalid_tables = [t for t in tables_to_update if t not in SUPPORTED_TABLES]
    if invalid_tables:
        logger.error(f"é”™è¯¯: ä¸æ”¯æŒçš„è¡¨å: {invalid_tables}")
        logger.info(f"æ”¯æŒçš„è¡¨å: {SUPPORTED_TABLES}")
        return
    
    logger.info(f"å‡†å¤‡æ›´æ–°è¡¨: {tables_to_update}")
    logger.info(f"è‚¡ç¥¨æ•°é‡: {len(stock_codes)}")
    
    # æ‰¹é‡æ›´æ–°æ•°æ®
    for table_name in tables_to_update:
        logger.info(f"\næ­£åœ¨æ›´æ–° {table_name} æ•°æ®...")
        
        if table_name == DataType.STOCK_LIST:
            result = api.update_stock_list(force_update=True)
        elif table_name == DataType.PRICE_DATA:
            # å†å²è¡¥é½ï¼šå¼ºåˆ¶å…¨é‡
            if getattr(args, 'bj_stocks', False):
                # åŒ—äº¤æ‰€è‚¡ç¥¨ä½¿ç”¨tushareæ•°æ®æºæ›´æ–°
                result = api.update_bj_stocks_data(stock_codes, data_types=[DataType.PRICE_DATA], force_full_update=True)
            else:
                # éåŒ—äº¤æ‰€è‚¡ç¥¨ä½¿ç”¨é»˜è®¤æ•°æ®æºæ›´æ–°
                result = api.update_data(stock_codes, data_types=[DataType.PRICE_DATA], force_full_update=True)
        elif table_name in ['balance_sheet', 'income_statement', 'cashflow_statement', 'financial_indicators']:
            # å†å²è¡¥é½ï¼šå¼ºåˆ¶å…¨é‡ï¼ˆè´¢åŠ¡ç±»ï¼‰
            result = api.update_data(stock_codes, data_types=['financial'], force_full_update=True)
        elif table_name == DataType.INDICATOR_DATA:
            # å†å²è¡¥é½ï¼šå¼ºåˆ¶å…¨é‡ï¼ˆæŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼‰
            if getattr(args, 'bj_stocks', False):
                # åŒ—äº¤æ‰€è‚¡ç¥¨ä½¿ç”¨tushareæ•°æ®æºæ›´æ–°
                result = api.update_bj_stocks_data(stock_codes, data_types=[DataType.INDICATOR_DATA], force_full_update=True)
            else:
                # éåŒ—äº¤æ‰€è‚¡ç¥¨ä½¿ç”¨é»˜è®¤æ•°æ®æºæ›´æ–°
                result = api.update_data(stock_codes, data_types=[DataType.INDICATOR_DATA], force_full_update=True)
        elif table_name == DataType.FUNDAMENTAL_DATA:
            # å†å²è¡¥é½ï¼šå¼ºåˆ¶å…¨é‡ï¼ˆåŸºæœ¬é¢æ•°æ®ï¼‰
            if getattr(args, 'bj_stocks', False):
                # åŒ—äº¤æ‰€è‚¡ç¥¨ä½¿ç”¨tushareæ•°æ®æºæ›´æ–°
                result = api.update_bj_stocks_data(stock_codes, data_types=[DataType.FUNDAMENTAL_DATA], force_full_update=True)
            else:
                # éåŒ—äº¤æ‰€è‚¡ç¥¨ä½¿ç”¨é»˜è®¤æ•°æ®æºæ›´æ–°
                result = api.update_data(stock_codes, data_types=[DataType.FUNDAMENTAL_DATA], force_full_update=True)
        else:
            logger.warning(f"è­¦å‘Š: æš‚ä¸æ”¯æŒæ›´æ–°è¡¨ {table_name}")
            continue
        
        if isinstance(result, dict) and result.get('success'):
            logger.info(f"{table_name} æ•°æ®æ›´æ–°å®Œæˆ")
        elif result:
            logger.info(f"{table_name} æ•°æ®æ›´æ–°å®Œæˆ")
        else:
            logger.error(f"{table_name} æ•°æ®æ›´æ–°å¤±è´¥")
    
    logger.info("\nå†å²æ•°æ®æ›´æ–°å®Œæˆ!")

    api.close()

def action_update_table(args):
    """
    æ›´æ–°æŒ‡å®šæ•°æ®è¡¨
    """
    if not args.table:
        logger.error("é”™è¯¯: è¯·æŒ‡å®šè¦æ›´æ–°çš„è¡¨å")
        return
    
    if args.table not in SUPPORTED_TABLES:
        logger.error(f"é”™è¯¯: ä¸æ”¯æŒçš„è¡¨å: {args.table}")
        logger.info(f"æ”¯æŒçš„è¡¨å: {SUPPORTED_TABLES}")
        return
    
    logger.info(f"å¼€å§‹æ›´æ–°è¡¨: {args.table}")
    
    api = create_api(db_path=args.db_path)
    
    try:
        api.initialize()
        
        if args.table == DataType.STOCK_LIST:
            result = api.update_stock_list(force_update=True)
            if result:
                logger.info("è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å®Œæˆ")
            else:
                logger.error("è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å¤±è´¥")
        else:
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            stock_codes = api.get_stock_list()
            if not stock_codes:
                logger.error("é”™è¯¯: æ•°æ®åº“ä¸­æ²¡æœ‰è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·å…ˆè¿è¡Œ init å‘½ä»¤")
                return
            
            logger.info(f"å‡†å¤‡æ›´æ–° {len(stock_codes)} åªè‚¡ç¥¨çš„ {args.table} æ•°æ®")
            
            # è®¡ç®—â€œæ—¥çº§åˆ«è¡¥é½â€çš„æˆªæ­¢æ—¥æœŸï¼š15ç‚¹åä¸ºä»Šå¤©ï¼Œå¦åˆ™ä¸ºæ˜¨å¤©
            now = datetime.now()
            end_date_cutoff = now.date() if now.hour >= 15 else (now.date() - timedelta(days=1))
            
            if args.table == DataType.PRICE_DATA:
                # æ—¥çº§åˆ«å¢é‡è¡¥é½ï¼šä»åº“é‡Œæœ€æ–°æ—¥æœŸ+1åˆ° end_date_cutoff
                result = api.update_data(stock_codes, data_types=[DataType.PRICE_DATA], end_date=end_date_cutoff)
            elif args.table in ['balance_sheet', 'income_statement', 'cashflow_statement', 'financial_indicators']:
                # è´¢åŠ¡ç±»ä¹ŸæŒ‰åŒä¸€æˆªæ­¢æ—¥ç­–ç•¥ï¼ˆä¸å¼ºåˆ¶å…¨é‡ï¼‰
                result = api.update_data(stock_codes, data_types=['financial'], end_date=end_date_cutoff)
            else:
                logger.warning(f"è­¦å‘Š: æš‚ä¸æ”¯æŒæ›´æ–°è¡¨ {args.table}")
                return
            
            if isinstance(result, dict) and result.get('success'):
                logger.info(f"{args.table} æ•°æ®æ›´æ–°å®Œæˆ")
            elif result:
                logger.info(f"{args.table} æ•°æ®æ›´æ–°å®Œæˆ")
            else:
                logger.error(f"{args.table} æ•°æ®æ›´æ–°å¤±è´¥")
        
    except Exception as e:
        logger.error(f"æ›´æ–°è¡¨å¤±è´¥: {e}")
        logging.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    finally:
        api.close()


def action_update_stock_list(args):
    """
    æ›´æ–°è‚¡ç¥¨åˆ—è¡¨
    """
    logger.info("å¼€å§‹æ›´æ–°è‚¡ç¥¨åˆ—è¡¨...")
    
    api = create_api(db_path=args.db_path)
    
    try:
        api.initialize()
        
        result = api.update_stock_list(force_update=True)
        if result:
            logger.info("è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å®Œæˆ")
            
            # æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯
            stocks = api.get_stock_list()
            logger.info(f"å½“å‰è‚¡ç¥¨æ€»æ•°: {len(stocks)}")
            
            market_stats = api.get_market_statistics()
            if market_stats:
                logger.info("å¸‚åœºåˆ†å¸ƒ:")
                for market, count in market_stats.items():
                    logger.info(f"  {market}: {count} åª")
        else:
            logger.error("è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å¤±è´¥")
        
    except Exception as e:
        logger.error(f"æ›´æ–°è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        logging.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    finally:
        api.close()

def send_feishu_quality_report(report, check_type="æ•°æ®è´¨é‡æ£€æŸ¥"):
    """
    å‘é€æ•°æ®è´¨é‡æŠ¥å‘Šåˆ°é£ä¹¦

    Args:
        report: QualityReportå¯¹è±¡
        check_type: æ£€æŸ¥ç±»å‹æè¿°
    """
    try:
        from common.feishu_client import FeishuWebhookBot
        import os
        from datetime import datetime

        # è·å–é£ä¹¦é…ç½®
        webhook_url = os.getenv('FEISHU_WEBHOOK_URL')
        secret = os.getenv('FEISHU_SECRET')

        if not webhook_url:
            logger.warning("æœªé…ç½®é£ä¹¦Webhook URLï¼Œè·³è¿‡é£ä¹¦é€šçŸ¥")
            return False

        # åˆ›å»ºé£ä¹¦å®¢æˆ·ç«¯
        feishu_bot = FeishuWebhookBot(webhook_url, secret)

        # æ„å»ºå¯Œæ–‡æœ¬æ¶ˆæ¯å†…å®¹
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # ç¡®å®šæ¶ˆæ¯é¢œè‰²å’ŒçŠ¶æ€
        if report.critical_issues > 0:
            status_emoji = "ğŸ”´"
            status_text = "å‘ç°ä¸¥é‡é—®é¢˜"
        elif report.warning_issues > 0:
            status_emoji = "ğŸŸ¡"
            status_text = "å‘ç°è­¦å‘Šé—®é¢˜"
        else:
            status_emoji = "ğŸŸ¢"
            status_text = "æ£€æŸ¥é€šè¿‡"

        # æ„å»ºå¯Œæ–‡æœ¬å†…å®¹ - ç®€åŒ–æ ¼å¼
        content = [
            # æ ‡é¢˜è¡Œ
            [
                {"tag": "text", "text": f"{status_emoji} {check_type}æŠ¥å‘Š"}
            ],
            # åŸºæœ¬ä¿¡æ¯åˆå¹¶åˆ°ä¸€è¡Œ
            [
                {"tag": "text", "text": f"ğŸ“… æ£€æŸ¥æ—¶é—´: {current_time}\nâ±ï¸ æ£€æŸ¥æ—¶é•¿: {report.summary.get('check_duration_seconds', 0):.1f}ç§’\nğŸ“Š æ£€æŸ¥è¡¨æ•°: {len(report.tables_checked)}\nğŸ” æ€»é—®é¢˜æ•°: {report.total_issues}"}
            ]
        ]

        # å¦‚æœæœ‰é—®é¢˜ï¼Œæ·»åŠ è¯¦ç»†ç»Ÿè®¡
        if report.total_issues > 0:
            problem_text = f"\nâŒ ä¸¥é‡é—®é¢˜: {report.critical_issues}ä¸ª\nâš ï¸ è­¦å‘Šé—®é¢˜: {report.warning_issues}ä¸ª"

            # æŒ‰è¡¨ç»Ÿè®¡é—®é¢˜
            table_stats = report.summary.get('table_stats', {})
            if table_stats:
                problem_text += "\n\nğŸ“‹ é—®é¢˜åˆ†å¸ƒ:"
                for table, stats in table_stats.items():
                    total_table_issues = stats.get('critical', 0) + stats.get('warning', 0) + stats.get('info', 0)
                    if total_table_issues > 0:
                        problem_text += f"\nâ€¢ {table}: {total_table_issues}ä¸ª (ä¸¥é‡:{stats.get('critical', 0)}, è­¦å‘Š:{stats.get('warning', 0)})"

            # æ˜¾ç¤ºå‰3ä¸ªæœ€é‡è¦çš„é—®é¢˜
            critical_issues = [issue for issue in report.issues if issue.severity == 'critical']
            warning_issues = [issue for issue in report.issues if issue.severity == 'warning']
            important_issues = critical_issues[:2] + warning_issues[:1]  # æœ€å¤šæ˜¾ç¤º3ä¸ªé—®é¢˜

            if important_issues:
                problem_text += "\n\nğŸš¨ ä¸»è¦é—®é¢˜:"
                for issue in important_issues:
                    severity_emoji = "âŒ" if issue.severity == 'critical' else "âš ï¸"
                    problem_text += f"\n{severity_emoji} [{issue.table}] {issue.description}"

            content.append([
                {"tag": "text", "text": problem_text}
            ])
        else:
            content.append([
                {"tag": "text", "text": "\nâœ… æœªå‘ç°æ•°æ®è´¨é‡é—®é¢˜ï¼Œæ•°æ®çŠ¶æ€è‰¯å¥½ï¼"}
            ])

        # å‘é€æ¶ˆæ¯
        title = f"è‚¡ç¥¨æ•°æ®åº“{check_type}æŠ¥å‘Š - {status_text}"
        result = feishu_bot.send_rich_text(content, title)

        if result.get('code') == 0:
            logger.info("é£ä¹¦é€šçŸ¥å‘é€æˆåŠŸ")
            return True
        else:
            logger.error(f"é£ä¹¦é€šçŸ¥å‘é€å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
            return False

    except Exception as e:
        logger.error(f"å‘é€é£ä¹¦é€šçŸ¥æ—¶å‡ºé”™: {e}")
        return False


def action_check_data(args):
    """
    æ•°æ®è´¨é‡æ£€æŸ¥
    """
    from services.data_quality_service import DataQualityService
    import json
    import os

    # è·å–æ£€æŸ¥å‚æ•°
    level = getattr(args, 'level', 'quick')
    tables = getattr(args, 'tables', None)
    output_report = getattr(args, 'output_report', None)
    daily_routine = getattr(args, 'daily_routine', False)
    recent_days = getattr(args, 'recent_days', 3)
    historical_sample_days = getattr(args, 'historical_sample_days', 30)
    no_feishu = getattr(args, 'no_feishu', False)

    if tables:
        tables = [t.strip() for t in tables.split(',')]

    # ç¡®å®šæ£€æŸ¥ç±»å‹
    if daily_routine:
        logger.info(f"å¼€å§‹æ—¥å¸¸ä¾‹è¡Œæ•°æ®è´¨é‡æ£€æŸ¥...")
        logger.info(f"- æœ€è¿‘{recent_days}ä¸ªäº¤æ˜“æ—¥å…¨é‡æ£€æŸ¥")
        logger.info(f"- å†å²{historical_sample_days}ä¸ªäº¤æ˜“æ—¥æŠ½æ ·æ£€æŸ¥")
    else:
        logger.info(f"å¼€å§‹{level}çº§åˆ«æ•°æ®è´¨é‡æ£€æŸ¥...")

    api = create_api(db_path=args.db_path)

    try:
        api.initialize()

        # åˆ›å»ºæ•°æ®è´¨é‡æœåŠ¡
        quality_service = DataQualityService(api)

        # æ‰§è¡Œæ£€æŸ¥
        if daily_routine:
            report = quality_service.daily_routine_check(
                recent_days=recent_days,
                historical_sample_days=historical_sample_days
            )
        else:
            report = quality_service.check_data_quality(level=level, tables=tables)

        # è¾“å‡ºæ£€æŸ¥ç»“æœæ‘˜è¦
        logger.info(f"\n=== æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š ===")
        if daily_routine:
            logger.info(f"æ£€æŸ¥ç±»å‹: æ—¥å¸¸ä¾‹è¡Œæ£€æŸ¥")
            logger.info(f"æœ€è¿‘äº¤æ˜“æ—¥: {report.summary.get('recent_days_checked', recent_days)}å¤©")
            logger.info(f"å†å²æŠ½æ ·: {report.summary.get('historical_sample_days', historical_sample_days)}å¤©")
        else:
            logger.info(f"æ£€æŸ¥çº§åˆ«: {report.check_level}")
        logger.info(f"æ£€æŸ¥æ—¶é•¿: {report.summary.get('check_duration_seconds', 0):.1f}ç§’")
        logger.info(f"æ£€æŸ¥è¡¨æ•°: {len(report.tables_checked)}")
        logger.info(f"å‘ç°é—®é¢˜: {report.total_issues}ä¸ª")

        if report.total_issues > 0:
            logger.info(f"  ä¸¥é‡é—®é¢˜: {report.critical_issues}ä¸ª")
            logger.info(f"  è­¦å‘Šé—®é¢˜: {report.warning_issues}ä¸ª")

            # æŒ‰è¡¨ç»Ÿè®¡é—®é¢˜
            table_stats = report.summary.get('table_stats', {})
            if table_stats:
                logger.info(f"\né—®é¢˜åˆ†å¸ƒ:")
                for table, stats in table_stats.items():
                    total_table_issues = stats.get('critical', 0) + stats.get('warning', 0) + stats.get('info', 0)
                    logger.info(f"  {table}: {total_table_issues}ä¸ªé—®é¢˜ "
                              f"(ä¸¥é‡:{stats.get('critical', 0)}, è­¦å‘Š:{stats.get('warning', 0)})")

            # æ˜¾ç¤ºé—®é¢˜æ˜ç»†
            logger.info(f"\né—®é¢˜æ˜ç»†:")
            for issue in report.issues:
                severity_prefix = "âŒ" if issue.severity == 'critical' else "âš ï¸" if issue.severity == 'warning' else "â„¹ï¸"
                logger.info(f"  {severity_prefix} [{issue.table}] {issue.description}")
                if issue.samples:
                    samples_str = ", ".join(issue.samples[:3])  # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
                    sample_count = len(issue.samples)
                    if sample_count > 3:
                        samples_str += f" (å…±{sample_count}ä¸ªæ ·æœ¬)"
                    logger.info(f"     æ ·æœ¬: {samples_str}")

            # æŒ‰ç±»åˆ«ç»Ÿè®¡é—®é¢˜
            category_stats = report.summary.get('category_stats', {})
            if category_stats:
                logger.info(f"\né—®é¢˜ç±»åˆ«:")
                logger.info(f"  å®Œæ•´æ€§: {category_stats.get('completeness', 0)}ä¸ª")
                logger.info(f"  å”¯ä¸€æ€§: {category_stats.get('uniqueness', 0)}ä¸ª")
                logger.info(f"  å‡†ç¡®æ€§: {category_stats.get('accuracy', 0)}ä¸ª")
        else:
            logger.info("æœªå‘ç°æ•°æ®è´¨é‡é—®é¢˜")

        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        if output_report:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_report), exist_ok=True)

            with open(output_report, 'w', encoding='utf-8') as f:
                json.dump(report.to_dict(), f, ensure_ascii=False, indent=2)

            logger.info(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_report}")
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œç”Ÿæˆé»˜è®¤æŠ¥å‘Šæ–‡ä»¶
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            default_report_path = f"logs/data_quality_report_{timestamp}.json"

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(default_report_path), exist_ok=True)

            with open(default_report_path, 'w', encoding='utf-8') as f:
                json.dump(report.to_dict(), f, ensure_ascii=False, indent=2)

            logger.info(f"\nè¯¦ç»†æŠ¥å‘Šå·²è‡ªåŠ¨ä¿å­˜åˆ°: {default_report_path}")

        # å‘é€é£ä¹¦é€šçŸ¥ï¼ˆå¦‚æœæœªç¦ç”¨ï¼‰
        if not no_feishu:
            check_type = "æ—¥å¸¸ä¾‹è¡Œæ£€æŸ¥" if daily_routine else f"{level}çº§åˆ«æ•°æ®è´¨é‡æ£€æŸ¥"
            logger.info("æ­£åœ¨å‘é€é£ä¹¦é€šçŸ¥...")
            feishu_success = send_feishu_quality_report(report, check_type)
            if not feishu_success:
                logger.warning("é£ä¹¦é€šçŸ¥å‘é€å¤±è´¥ï¼Œä½†ä¸å½±å“æ£€æŸ¥ç»“æœ")

        # å¦‚æœæœ‰ä¸¥é‡é—®é¢˜ï¼Œæé†’ç”¨æˆ·æ³¨æ„
        if report.critical_issues > 0:
            logger.error(f"\nå‘ç°{report.critical_issues}ä¸ªä¸¥é‡æ•°æ®è´¨é‡é—®é¢˜ï¼Œå»ºè®®ç«‹å³å¤„ç†ï¼")
            return False
        elif report.warning_issues > 0:
            logger.warning(f"\nå‘ç°{report.warning_issues}ä¸ªè­¦å‘Šçº§åˆ«é—®é¢˜ï¼Œå»ºè®®å…³æ³¨ã€‚")

        return True

    except Exception as e:
        logger.error(f"æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
        logging.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        return False
    finally:
        api.close()